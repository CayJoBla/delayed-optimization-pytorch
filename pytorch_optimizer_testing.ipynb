{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delay_optimizer.delays.utils import ParamHistoryBuffer\n",
    "from delay_optimizer.delays.distributions import Stochastic\n",
    "import torch\n",
    "\n",
    "shape = (10,20,30)\n",
    "max_L = 3\n",
    "\n",
    "delay = Stochastic(max_L=max_L)\n",
    "param = torch.rand(shape)\n",
    "buffer = ParamHistoryBuffer(param, buffer_size=max_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.1 ms ± 2.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "num_iters = 1000\n",
    "for _ in range(num_iters):\n",
    "    new_param = torch.rand(shape)\n",
    "    buffer.update(new_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.6 ms ± 3.59 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "num_iters = 1000\n",
    "for i in range(num_iters):\n",
    "    delay.sample(shape, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.8 ms ± 790 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "num_iters = 1000\n",
    "max_L = 100\n",
    "temp_buffer = ParamHistoryBuffer(torch.rand(shape), buffer_size=max_L)\n",
    "for i in range(num_iters):\n",
    "    new_param = torch.rand(shape)\n",
    "    temp_buffer.update(new_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 ms ± 25.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "num_iters = 1000\n",
    "max_L = 100\n",
    "temp_buffer = torch.stack([torch.rand(shape).clone().detach() for _ in range(max_L)], dim=0)\n",
    "for i in range(num_iters):\n",
    "    new_param = torch.rand(shape)\n",
    "    full_param_state = torch.cat([new_param.detach().unsqueeze(0), temp_buffer], dim=0)\n",
    "    temp_buffer = full_param_state[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 ms ± 4.36 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "num_iters = 1000\n",
    "max_L = 3\n",
    "temp_buffer = torch.stack([torch.rand(shape).clone().detach() for _ in range(max_L)], dim=0)\n",
    "delay = Stochastic(max_L=max_L)\n",
    "for i in range(num_iters):\n",
    "    new_param = torch.rand(shape)\n",
    "    full_param_state = torch.cat([new_param.detach().unsqueeze(0), temp_buffer], dim=0)\n",
    "    D = delay.sample(shape, i)\n",
    "    delayed_param = full_param_state.gather(0, D.unsqueeze(0)).squeeze(0)\n",
    "    temp_buffer = full_param_state[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.4 s ± 1.02 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "num_iters = 1000\n",
    "max_L = 3\n",
    "temp_param = torch.rand(shape)  \n",
    "temp_buffer = ParamHistoryBuffer(temp_param, buffer_size=max_L)\n",
    "delay = Stochastic(max_L=max_L)\n",
    "for i in range(num_iters):\n",
    "    new_param = torch.rand(shape)\n",
    "    temp_param, temp_buffer = delay(new_param, temp_buffer, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 ms ± 391 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "num_iters = 1000\n",
    "max_L = 3\n",
    "temp_buffer = torch.stack([torch.rand(shape).clone().detach() for _ in range(max_L)], dim=0)\n",
    "delay = Stochastic(max_L=max_L)\n",
    "for i in range(num_iters):\n",
    "    new_param = torch.rand(shape)\n",
    "    full_param_state = torch.stack([new_param.detach()] + list(temp_buffer), dim=0)\n",
    "    D = delay.sample(shape, i)\n",
    "    delayed_param = full_param_state.gather(0, D.unsqueeze(0)).squeeze(0)\n",
    "    temp_buffer = full_param_state[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.linear = nn.Linear(5, 6)\n",
    "        self.linear.weight.data.fill_(1.0)\n",
    "        self.linear.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(self.linear.weight)\n",
    "        print(self.linear.bias)\n",
    "        return self.linear(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamHistoryBuffer:\n",
    "    \"\"\"Holds the parameter history and manages delays for a single parameter.\"\"\"\n",
    "    def __init__(self, param, buffer_size):\n",
    "        self.buffer_size = buffer_size      # Should be max_L+1\n",
    "        self._buffer = param.repeat(self.buffer_size, *(1,)*param.ndim).detach()\n",
    "        self._current_idx = 0\n",
    "\n",
    "    @property\n",
    "    def parameter(self):\n",
    "        return self._buffer[self._current_idx]\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._buffer, name)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\"ParamHistoryBuffer(\\n\"\n",
    "                f\"{self._buffer}, current_idx={self._current_idx})\")\n",
    "\n",
    "    def _delay_to_idx(self, delay):\n",
    "        if any(delay < 0) or any(delay > (self.buffer_size-1)):\n",
    "            raise IndexError(f\"Delay must be in [0, {self.buffer_size-1}]\")\n",
    "        return (self._current_idx + delay) % self.buffer_size\n",
    "\n",
    "    def __getitem__(self, args):\n",
    "        delay, *args = args if isinstance(args, tuple) else (args,)\n",
    "        if isinstance(delay, slice):\n",
    "             raise ValueError(\"Slicing is not supported over the delay dimension.\")\n",
    "        return self._buffer[self._delay_to_idx(delay), *args]\n",
    "\n",
    "    def update(self, new_param):\n",
    "        self._current_idx = (self._current_idx - 1) % self.buffer_size\n",
    "        self._buffer[self._current_idx] = new_param\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = SimpleModel()\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'old_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, params \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[1;32m      3\u001b[0m     buffers\u001b[38;5;241m.\u001b[39mappend(ParamHistoryBuffer(params, buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mold_params\u001b[49m[name] \u001b[38;5;241m=\u001b[39m buffers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mparameter\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      8\u001b[0m     random_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'old_params' is not defined"
     ]
    }
   ],
   "source": [
    "b\n",
    "\n",
    "for i in range(3):\n",
    "    random_input = torch.randn(1,5)\n",
    "    random_out = model(random_input)\n",
    "    for buffer in buffers:\n",
    "        buffer.update(torch.randint(0, 4, buffer.parameter.shape))\n",
    "\n",
    "        print(buffer)\n",
    "\n",
    "    \n",
    "\n",
    "# # leaf variable with requires_grad=True can not used inplace operation\n",
    "# for name, params in model.named_parameters():\n",
    "#     params.data.copy_(old_params[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delayed_opt_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
