{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TestModel(nn.Module):\n",
    "    def __init__(self, input_size=3, intermediate_size=5, output_size=2):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, intermediate_size)\n",
    "        self.fc2 = nn.Linear(intermediate_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.fc1(x))\n",
    "\n",
    "model = TestModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import torch\n",
    "from pytorch_optimizer import DelayedOptimizationWrapper\n",
    "from delay_optimizer.delays.distributions import Stochastic, Undelayed\n",
    "\n",
    "bias_params = [p for n, p in model.named_parameters() if \"bias\" in n]\n",
    "non_bias_params = [p for n, p in model.named_parameters() if \"bias\" not in n]\n",
    "optimizer = DelayedOptimizationWrapper(Adam([{\"params\": bias_params, \"delay\": Undelayed()},{\"params\": non_bias_params, \"delay\":Stochastic(3, 1000)}], lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DelayedOptimizationWrapper (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    delay: Undelayed\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    history: [tensor([], size=(0, 5)), tensor([], size=(0, 2))]\n",
       "    lr: 0.01\n",
       "    max_L: 0\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    delay: Stochastic\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    history: [tensor([[[ 5.3105e-01,  6.8636e-02, -5.2133e-01],\n",
       "         [ 2.3278e-01,  5.1172e-01,  3.4246e-01],\n",
       "         [-6.9846e-02,  1.7337e-05,  2.4849e-01],\n",
       "         [-2.2138e-01,  1.1057e-01,  4.9824e-01],\n",
       "         [-5.3136e-02,  4.3500e-01, -5.1018e-01]],\n",
       "\n",
       "        [[ 5.3105e-01,  6.8636e-02, -5.2133e-01],\n",
       "         [ 2.3278e-01,  5.1172e-01,  3.4246e-01],\n",
       "         [-6.9846e-02,  1.7337e-05,  2.4849e-01],\n",
       "         [-2.2138e-01,  1.1057e-01,  4.9824e-01],\n",
       "         [-5.3136e-02,  4.3500e-01, -5.1018e-01]],\n",
       "\n",
       "        [[ 5.3105e-01,  6.8636e-02, -5.2133e-01],\n",
       "         [ 2.3278e-01,  5.1172e-01,  3.4246e-01],\n",
       "         [-6.9846e-02,  1.7337e-05,  2.4849e-01],\n",
       "         [-2.2138e-01,  1.1057e-01,  4.9824e-01],\n",
       "         [-5.3136e-02,  4.3500e-01, -5.1018e-01]]]), tensor([[[ 0.3644,  0.2767,  0.0180,  0.2439,  0.1646],\n",
       "         [ 0.2922,  0.0944,  0.1670, -0.1592,  0.3191]],\n",
       "\n",
       "        [[ 0.3644,  0.2767,  0.0180,  0.2439,  0.1646],\n",
       "         [ 0.2922,  0.0944,  0.1670, -0.1592,  0.3191]],\n",
       "\n",
       "        [[ 0.3644,  0.2767,  0.0180,  0.2439,  0.1646],\n",
       "         [ 0.2922,  0.0944,  0.1670, -0.1592,  0.3191]]])]\n",
       "    lr: 0.01\n",
       "    max_L: 3\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "optimizer.apply_delays()\n",
    "\n",
    "x = torch.randn(1, 3)\n",
    "y = model(x)\n",
    "loss = torch.square(y).sum()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state[bias_params[0]].get(\"step\", torch.tensor(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_history = torch.randint(0, 100, (1, 3))\n",
    "param = torch.tensor([1.0, 2.0, 3.0])\n",
    "L =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[[2., 2., 2.],\n",
      "         [2., 2., 2.],\n",
      "         [2., 2., 2.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[3., 3., 3.],\n",
      "         [3., 3., 3.],\n",
      "         [3., 3., 3.],\n",
      "         [3., 3., 3.]]], dtype=torch.float64)\n",
      "tensor([[2, 1, 2],\n",
      "        [1, 1, 0],\n",
      "        [0, 0, 1],\n",
      "        [2, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "\n",
    "shape = (4,3)\n",
    "L = 2\n",
    "param_state = torch.full(shape, 1.)\n",
    "# param_history = deque([torch.full(shape, i+L, dtype=float) \n",
    "#                         for i in range(L)], maxlen=L)\n",
    "param_history = torch.stack([torch.full(shape, i+L, dtype=float) for i in range(L)], dim=0)\n",
    "D = torch.randint(0, L+1, shape)\n",
    "\n",
    "print(param_state)\n",
    "print(param_history)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True],\n",
      "        [ True,  True,  True],\n",
      "        [False, False, False],\n",
      "        [ True,  True, False]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [1., 1., 1.],\n",
      "        [3., 3., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]], dtype=torch.float64)\n",
      "tensor([[2., 2., 2.],\n",
      "        [3., 3., 3.],\n",
      "        [1., 1., 1.],\n",
      "        [3., 3., 1.]])\n",
      "tensor([[[2., 2., 2.],\n",
      "         [2., 2., 2.],\n",
      "         [2., 2., 2.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[3., 3., 3.],\n",
      "         [3., 3., 3.],\n",
      "         [3., 3., 3.],\n",
      "         [3., 3., 3.]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Create a mask where D > 0\n",
    "mask = D > 0\n",
    "print(mask)\n",
    "\n",
    "# Directly extract only the required delayed values from param_history\n",
    "initial_param_state = param_state.clone().detach()\n",
    "print(initial_param_state)\n",
    "\n",
    "# delayed_values = [param_history[d][i, j].item() for d, i, j in \n",
    "                    # zip(D[mask]-1, *mask.nonzero(as_tuple=True))]\n",
    "delayed_values = param_history[D[mask]-1, *mask.nonzero(as_tuple=True)]\n",
    "print(delayed_values)\n",
    "\n",
    "# Perform the update in-place on param_state\n",
    "# param_state[mask] = torch.tensor(delayed_values, dtype=param_state.dtype)\n",
    "print(param_state)\n",
    "\n",
    "# Prepend the current param_state to param_history and drop the oldest\n",
    "# param_history.appendleft(initial_param_state)   # maxlen=L so oldest is dropped\n",
    "print(param_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamHistoryBuffer:\n",
    "    \"\"\"Holds the parameter history and manages delays for a single parameter.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        param,\n",
    "        buffer_size,\n",
    "        device = None,\n",
    "    ):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.device = device or param.device\n",
    "\n",
    "        self._initialize_history(param)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"ParamHistoryBuffer({self._buffer}, \"\n",
    "                f\"current_idx={self._current_idx})\")\n",
    "\n",
    "    def _initialize_history(self, param):\n",
    "        \"\"\"Initialize the history with L copies of the current parameter.\"\"\"\n",
    "        self._buffer = param.repeat(self.buffer_size, *(1,)*param.ndim)\n",
    "        self._current_idx = 0\n",
    "        \n",
    "    def _delay_to_idx(self, delay):\n",
    "        if delay <= 0 or delay > self.buffer_size:\n",
    "            raise IndexError(f\"Delay must be in [1, {self.buffer_size}]\")\n",
    "        return (self._current_idx + delay - 1) % self.buffer_size\n",
    "\n",
    "    def __getitem__(self, args):\n",
    "        delay, *args = args if isinstance(args, tuple) else (args,)\n",
    "        if isinstance(delay, slice):\n",
    "             raise ValueError(\"Slicing over delays in parameter history \"\n",
    "                                \"is not supported.\")\n",
    "        return self._buffer[self._delay_to_idx(delay), *args[1:]]\n",
    "\n",
    "    def update(self, new_param):\n",
    "        self._current_idx = (self._current_idx - 1) % self.buffer_size\n",
    "        self._buffer[self._current_idx] = new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_history = ParamHistoryBuffer(param_state, 4)\n",
    "param_history.update(torch.full(param_state.shape, 4.0))  # delay of 3\n",
    "param_history.update(torch.full(param_state.shape, 3.0))  # delay of 2\n",
    "param_history.update(torch.full(param_state.shape, 2.0))  # delay of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParamHistoryBuffer(tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[2., 2., 2.],\n",
      "         [2., 2., 2.],\n",
      "         [2., 2., 2.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[3., 3., 3.],\n",
      "         [3., 3., 3.],\n",
      "         [3., 3., 3.],\n",
      "         [3., 3., 3.]],\n",
      "\n",
      "        [[4., 4., 4.],\n",
      "         [4., 4., 4.],\n",
      "         [4., 4., 4.],\n",
      "         [4., 4., 4.]]]), current_idx=1)\n"
     ]
    }
   ],
   "source": [
    "print(param_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True],\n",
      "        [ True,  True,  True],\n",
      "        [False, False, False],\n",
      "        [ True,  True, False]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "(tensor([2, 1, 2, 1, 1, 0, 2, 1]), tensor([0, 0, 0, 1, 1, 2, 3, 3, 3]), tensor([0, 1, 2, 0, 1, 2, 0, 1, 2]))\n",
      "((tensor([2, 1, 2, 1, 1, 0, 2, 1]), tensor([0, 0, 0, 1, 1, 2, 3, 3, 3]), tensor([0, 1, 2, 0, 1, 2, 0, 1, 2])),)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(initial_param_state)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# delayed_values = [param_history[d][i, j].item() for d, i, j in \u001b[39;00m\n\u001b[1;32m     10\u001b[0m                     \u001b[38;5;66;03m# zip(D[mask]-1, *mask.nonzero(as_tuple=True))]\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m delayed_values \u001b[38;5;241m=\u001b[39m \u001b[43mparam_history\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnonzero_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(delayed_values)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Perform the update in-place on param_state\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[37], line 30\u001b[0m, in \u001b[0;36mParamHistoryBuffer.__getitem__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(delay)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(args)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delay_to_idx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs[\u001b[38;5;241m1\u001b[39m:]]\n",
      "Cell \u001b[0;32mIn[37], line 22\u001b[0m, in \u001b[0;36mParamHistoryBuffer._delay_to_idx\u001b[0;34m(self, delay)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_delay_to_idx\u001b[39m(\u001b[38;5;28mself\u001b[39m, delay):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdelay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelay length must be positive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_idx \u001b[38;5;241m+\u001b[39m delay \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "# Create a mask where D > 0\n",
    "nonzero_mask = D > 0\n",
    "print(mask)\n",
    "\n",
    "# Directly extract only the required delayed values from param_history\n",
    "initial_param_state = param_state.clone().detach()\n",
    "print(initial_param_state)\n",
    "\n",
    "# delayed_values = [param_history[d][i, j].item() for d, i, j in \n",
    "                    # zip(D[mask]-1, *mask.nonzero(as_tuple=True))]\n",
    "delayed_values = param_history[D[mask], *nonzero_mask.nonzero(as_tuple=True)]\n",
    "print(delayed_values)\n",
    "\n",
    "# Perform the update in-place on param_state\n",
    "param_state[mask] = torch.tensor(delayed_values, dtype=param_state.dtype)\n",
    "print(param_state)\n",
    "\n",
    "# Prepend the current param_state to param_history and drop the oldest\n",
    "# param_history.appendleft(initial_param_state)   # maxlen=L so oldest is dropped\n",
    "print(param_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.deque' object has no attribute 'gather'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m time_indices \u001b[38;5;241m=\u001b[39m (D[mask] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Use gather to extract the delayed values from param_history\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# param_history is assumed to have shape [L, *param.shape]\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m delayed_values \u001b[38;5;241m=\u001b[39m \u001b[43mparam_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m(\u001b[38;5;241m0\u001b[39m, time_indices\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mparam_state\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Assign the delayed values back to param_state\u001b[39;00m\n\u001b[1;32m     12\u001b[0m param_state[mask] \u001b[38;5;241m=\u001b[39m delayed_values\u001b[38;5;241m.\u001b[39mto(param_state\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.deque' object has no attribute 'gather'"
     ]
    }
   ],
   "source": [
    "mask = D > 0\n",
    "indices = mask.nonzero(as_tuple=True)  # Get the indices where the mask is True\n",
    "\n",
    "# Extract the indices for the first dimension of param_history\n",
    "time_indices = (D[mask] - 1).long()\n",
    "\n",
    "# Use gather to extract the delayed values from param_history\n",
    "# param_history is assumed to have shape [L, *param.shape]\n",
    "delayed_values = param_history.gather(0, time_indices.unsqueeze(1).unsqueeze(2).expand(-1, *param_state.shape[1:]))\n",
    "\n",
    "# Assign the delayed values back to param_state\n",
    "param_state[mask] = delayed_values.to(param_state.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 1.],\n",
       "        [2., 1., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [2., 1., 2.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delay_old(param, param_history, D):\n",
    "    full_param_state = torch.cat([param.detach().unsqueeze(0), param_history], dim=0)\n",
    "    param.data.copy_(full_param_state.gather(0, D.unsqueeze(0)).squeeze(0))\n",
    "    param_history.data.copy_(full_param_state[:-1])\n",
    "    return param, param_history\n",
    "\n",
    "def delay_inplace(param, param_history, D):\n",
    "    full_param_state = torch.cat([param.detach().unsqueeze(0), param_history], dim=0)\n",
    "    param.copy_(full_param_state.gather(0, D).squeeze(0))\n",
    "    param_history.copy_(full_param_state[:-1])\n",
    "    return param, param_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (32,64)\n",
    "L = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1 ms ± 256 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "param = torch.rand(shape)\n",
    "param_history = deque([torch.rand(shape) for i in range(L)], maxlen=L)\n",
    "param_history_tensor = torch.stack(list(param_history))\n",
    "\n",
    "for i in range(50):\n",
    "    D = torch.randint(0, L, shape)\n",
    "    param, param_history_tensor = delay_old(param, param_history_tensor, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparam = torch.rand(shape)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mparam_history = deque([torch.rand(shape) for i in range(L)], maxlen=L)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mparam_history_tensor = torch.stack(list(param_history))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mfor i in range(50):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    D = torch.randint(0, L, shape)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    param, param_history_tensor = delay_inplace(param, param_history_tensor, D)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DelayedOptimization/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/DelayedOptimization/.venv/lib/python3.10/site-packages/IPython/core/magics/execution.py:1170\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m   1169\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m index\n\u001b[0;32m-> 1170\u001b[0m     time_number \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1172\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/DelayedOptimization/.venv/lib/python3.10/site-packages/IPython/core/magics/execution.py:158\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    156\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:7\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "Cell \u001b[0;32mIn[129], line 9\u001b[0m, in \u001b[0;36mdelay_inplace\u001b[0;34m(param, param_history, D)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelay_inplace\u001b[39m(param, param_history, D):\n\u001b[1;32m      8\u001b[0m     full_param_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([param\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), param_history], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     param\u001b[38;5;241m.\u001b[39mcopy_(\u001b[43mfull_param_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     10\u001b[0m     param_history\u001b[38;5;241m.\u001b[39mcopy_(full_param_state[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m param, param_history\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "param = torch.rand(shape)\n",
    "param_history = deque([torch.rand(shape) for i in range(L)], maxlen=L)\n",
    "param_history_tensor = torch.stack(list(param_history))\n",
    "\n",
    "for i in range(50):\n",
    "    D = torch.randint(0, L, shape)\n",
    "    param, param_history_tensor = delay_inplace(param, param_history_tensor, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0847, 0.0033, 0.5999],\n",
      "        [0.6128, 0.8855, 0.4476]])\n",
      "tensor([[[0.9649, 0.7076, 0.5187],\n",
      "         [0.0799, 0.9483, 0.1927]],\n",
      "\n",
      "        [[0.6909, 0.8019, 0.1471],\n",
      "         [0.9378, 0.4082, 0.7502]]])\n",
      "tensor([[0.9649, 0.8019, 0.5999],\n",
      "        [0.6128, 0.9483, 0.4476]])\n",
      "tensor([[[0.0847, 0.0033, 0.5999],\n",
      "         [0.6128, 0.8855, 0.4476]],\n",
      "\n",
      "        [[0.9649, 0.7076, 0.5187],\n",
      "         [0.0799, 0.9483, 0.1927]]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "L = 2\n",
    "\n",
    "param = torch.rand(shape)\n",
    "param_history = deque([torch.rand(shape) for i in range(L)], maxlen=L)\n",
    "param_history_tensor = torch.stack(list(param_history))\n",
    "D = torch.tensor([[1, 2, 0], \n",
    "                  [0, 1, 0]])\n",
    "\n",
    "print(param)\n",
    "print(param_history_tensor)\n",
    "\n",
    "delay_inplace(param, param_history_tensor, D)\n",
    "\n",
    "print(param)\n",
    "print(param_history_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "\n",
    "def get_test_params(filename=\"test_params.pt\"):\n",
    "    class XOR:\n",
    "        def __init__(self):\n",
    "            self.fc1 = nn.Linear(2,10)\n",
    "            self.fc2 = nn.Linear(10,2)\n",
    "            self.relu = nn.ReLU()\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "    if filename in os.listdir():\n",
    "        return torch.load(filename)\n",
    "    else:\n",
    "        \n",
    "        model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_test_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mget_test_params\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      9\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m     10\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     11\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(filename)\n",
      "File \u001b[0;32m~/anaconda3/envs/delayed_opt_pt/lib/python3.12/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "get_test_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delayed_opt_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
